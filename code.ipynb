{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d2e499-4ee3-4a5d-9358-3ed2f3e5912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.evaluate.metrics import answer_exact_match\n",
    "from dspy.teleprompt import *\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "from typing import Literal\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3dcaf2-4849-4cc1-b166-3a51c55c2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and configure\n",
    "lm = dspy.LM('openai/unsloth/Llama-3.2-3B-Instruct', api_base=\"http://0.0.0.0:8000/v1\", api_key=\"token-abc@123\",model_type='text')\n",
    "# ollama_lm = dspy.LM('ollama_chat/llama3.2:1b', api_base=\"http://localhost:11434\", api_key=\"\")\n",
    "# hf_lm = dspy.LM('huggingface/meta-llama/Llama-3.2-3B-Instruct')\n",
    "\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d629eb3b-3018-453d-ba83-370aa07b5ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='so love'\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify emotion.\"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['very funny', 'so love'] = dspy.OutputField()\n",
    "\n",
    "sentence = \"i love you \"\n",
    "\n",
    "classify = dspy.Predict(Emotion)\n",
    "classify(sentence=sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5c8ac3-f754-4f10-a65f-75b3f479b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get history\n",
    "def get_history(lm, n):\n",
    "    history = lm.history\n",
    "    last_history = {}\n",
    "    if len(history) >= n:\n",
    "        last_history['system'] = history[-n:][0]['messages'][0]['content']\n",
    "        last_history['user'] = history[-n:][0]['messages'][1]['content']\n",
    "    return last_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cb2d31-ccd2-4665-ae00-74cecae076e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- SYSTEM ----\n",
      "Your input fields are:\n",
      "1. `sentence` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `sentiment` (typing.Literal[very funny, so love])\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "{sentence}\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "{sentiment}        # note: the value you produce must be one of: very funny; so love\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify emotion.\n",
      "---- USER ----\n",
      "[[ ## sentence ## ]]\n",
      "i love you \n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## sentiment ## ]]` (must be formatted as a valid Python typing.Literal[very funny, so love]), and then ending with the marker for `[[ ## completed ## ]]`.\n"
     ]
    }
   ],
   "source": [
    "#Inspect history\n",
    "history = get_history(lm,1)\n",
    "for k,v in history.items():\n",
    "    print('----', k.upper(), '----')\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9d0223-41b0-44c9-b792-450db1090dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Signature\n",
    "class ForestHealth(dspy.Signature):\n",
    "    \"\"\"Classify the health status of the forest, based on the given parameters. Also use column description for reference.\n",
    "       Output should be in lowercase.\"\"\"\n",
    "    parameters = dspy.InputField(desc=\"comprehensive collection of ecological and environmental measurements focused on tree characteristics and site conditions.\")\n",
    "    answer: Literal['very healthy', 'healthy', 'sub-healthy', 'unhealthy'] = dspy.OutputField(desc=\"labels matching the health status of forest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d556d3f-bceb-45da-8b10-5575341b8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Module\n",
    "class Classification(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.cot = dspy.ChainOfThought(ForestHealth)\n",
    "    \n",
    "    def forward(self, parameters):\n",
    "        response = self.cot(parameters=parameters)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68996c1d-9de1-469f-bed7-6ded007a6894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Process dataframe\n",
    "def proess_df(df, input_columns, output_column):\n",
    "    processed_df = pd.DataFrame()\n",
    "    formatted_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        new_row = ', '.join(\n",
    "            f\"{col} is {round(val) if isinstance(val, float) else val}\" \n",
    "            for col, val in zip(input_columns, row)\n",
    "        )\n",
    "        formatted_rows.append(new_row)\n",
    "    processed_df['parameters'] = formatted_rows\n",
    "    processed_df['health_status'] = df[output_column]\n",
    "    processed_df = processed_df.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36314e01-0a15-4ee4-93be-de199743e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set:  600\n",
      "Train set columns:  ['parameters', 'answer']\n",
      "Length of test set:  200\n",
      "Test set columns:  ['parameters', 'answer']\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "\n",
    "input_columns = ['latitude', 'longitude', 'diameter_at_breast_height', 'tree_height', 'crown_width_north_south', 'crown_width_east_west', 'slope', 'elevation', 'temperature', 'humidity', 'soil_total_nitrogen', 'soil_total_phosphorus', 'soil_available_phosphorus', 'soil_available_nitrogen', 'menhinick_index', 'gleason_index', 'disturbance_level', 'fire_risk_index']\n",
    "output_column = ['health_status']\n",
    "processed_test_df = proess_df(test_df, input_columns, output_column)\n",
    "processed_train_df = proess_df(train_df, input_columns, output_column)\n",
    "\n",
    "test_set = [dspy.Example(parameters=row['parameters'],\n",
    "                          answer=row['health_status']).with_inputs(\"parameters\",) for index, row in processed_test_df.iterrows()]\n",
    "train_set = [dspy.Example(parameters=row['parameters'],\n",
    "                          answer=row['health_status']).with_inputs(\"parameters\") for index, row in processed_train_df.iterrows()]\n",
    "\n",
    "print('Length of train set: ', len(train_set))\n",
    "print('Train set columns: ', list(train_set[0].keys()))\n",
    "print('Length of test set: ', len(test_set))\n",
    "print('Test set columns: ', list(test_set[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928e148d-aced-4bed-a0d7-43ae75dd14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classifier \n",
    "classifier = Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a33026-354d-40e7-aaf1-dd7b9f015856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='the forest is classified as sub-healthy due to the presence of a disturbance level of 2, indicating some level of stress or damage to the forest ecosystem. However, the menhinick index is 0, suggesting no visible signs of disease or insect infestation. The gleason index is 1, indicating a relatively low level of competition among trees. The soil parameters are relatively balanced, with adequate nitrogen and phosphorus levels. The temperature and humidity are within normal ranges. The slope is moderate, but not extreme. Overall, the forest appears to be experiencing some stress, but it is not severely impacted.',\n",
      "    answer='sub-healthy'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Single prediction\n",
    "output = classifier(parameters=processed_test_df.loc[25, 'parameters'])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa91a9d-6df3-4d12-8a28-5783e7a5aa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 200 (16.0%): 100%|███████████████████| 200/200 [06:40<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/24 08:52:58 INFO dspy.evaluate.evaluate: Average Metric: 32 / 200 (16.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Define evaluator and evaluate program\n",
    "evaluate_program = Evaluate(devset=test_set, metric=answer_exact_match, \n",
    "                            num_threads=8, display_progress=True, \n",
    "                            provide_traceback=True)\n",
    "eval_result=evaluate_program(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef41ffa-3019-40c2-a761-727709dd2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimiser (adding few-shot samples)\n",
    "teleprompter_fsrs = BootstrapFewShotWithRandomSearch(metric=answer_exact_match, \n",
    "                                                     max_labeled_demos=5)\n",
    "                                            \n",
    "optimised_classifier = teleprompter_fsrs.compile(classifier, trainset=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23cfe1e-50f3-452a-90fc-1abd56850388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate optimised program\n",
    "new_eval_result=evaluate_program(optimised_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d70285-bb96-44ef-9e21-31d941c7c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "save_path = 'forest_health_classification.json'\n",
    "optimized_classifier.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9215dd-8921-41df-b5e1-141a08ef6354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24059418-deef-472f-95d5-5b943842b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
